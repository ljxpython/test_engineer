# è´Ÿè½½ä¸å‹åŠ›æµ‹è¯•ä¸“é¢˜

## ä¸“é¢˜æ¦‚è¿°
æœ¬ä¸“é¢˜æ¶µç›–æ€§èƒ½æµ‹è¯•çš„æ ¸å¿ƒç†è®ºã€å·¥å…·ä½¿ç”¨ã€æµ‹è¯•ç­–ç•¥è®¾è®¡ç­‰å†…å®¹ï¼Œæ˜¯é«˜çº§æµ‹è¯•å¼€å‘å·¥ç¨‹å¸ˆåœ¨æ€§èƒ½ä¿éšœæ–¹é¢çš„å…³é”®æŠ€èƒ½ã€‚

**æ ¸å¿ƒæŠ€èƒ½ç‚¹**ï¼š
- è´Ÿè½½æµ‹è¯•ä¸å‹åŠ›æµ‹è¯•çš„åŒºåˆ«ä¸åº”ç”¨
- JMeterã€Locustç­‰æ€§èƒ½æµ‹è¯•å·¥å…·
- æ€§èƒ½æµ‹è¯•æŒ‡æ ‡ä½“ç³»
- æ€§èƒ½ç“¶é¢ˆåˆ†æä¸è°ƒä¼˜
- å®¹é‡è§„åˆ’ä¸é¢„æµ‹
- åˆ†å¸ƒå¼æ€§èƒ½æµ‹è¯•æ¶æ„

---

## é¢˜ç›®åˆ—è¡¨

### â­â­â­ è´Ÿè½½æµ‹è¯•vså‹åŠ›æµ‹è¯•vså®¹é‡æµ‹è¯•çš„åŒºåˆ«
**éš¾åº¦**ï¼šâ­â­â­  
**é¢‘ç‡**ï¼šğŸ”¥ğŸ”¥ğŸ”¥

**æ ‡å‡†ç­”æ¡ˆ**ï¼š
**æ€§èƒ½æµ‹è¯•åˆ†ç±»è¯¦è§£**ï¼š

1. **è´Ÿè½½æµ‹è¯•ï¼ˆLoad Testingï¼‰**ï¼š
   - **ç›®çš„**ï¼šéªŒè¯ç³»ç»Ÿåœ¨é¢„æœŸè´Ÿè½½ä¸‹çš„æ€§èƒ½è¡¨ç°
   - **è´Ÿè½½ç‰¹ç‚¹**ï¼šæ­£å¸¸æˆ–ç¨é«˜äºæ­£å¸¸çš„ç”¨æˆ·è´Ÿè½½
   - **å…³æ³¨æŒ‡æ ‡**ï¼šå“åº”æ—¶é—´ã€ååé‡ã€èµ„æºåˆ©ç”¨ç‡
   - **æµ‹è¯•åœºæ™¯**ï¼šæ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒçš„å…¸å‹ä½¿ç”¨åœºæ™¯

2. **å‹åŠ›æµ‹è¯•ï¼ˆStress Testingï¼‰**ï¼š
   - **ç›®çš„**ï¼šæ‰¾å‡ºç³»ç»Ÿçš„æ€§èƒ½æé™å’Œå¤±æ•ˆç‚¹
   - **è´Ÿè½½ç‰¹ç‚¹**ï¼šé€æ­¥å¢åŠ è´Ÿè½½ç›´åˆ°ç³»ç»Ÿå´©æºƒ
   - **å…³æ³¨æŒ‡æ ‡**ï¼šæœ€å¤§æ‰¿è½½èƒ½åŠ›ã€å¤±æ•ˆæ¨¡å¼ã€æ¢å¤èƒ½åŠ›
   - **æµ‹è¯•åœºæ™¯**ï¼šè¶…å‡ºæ­£å¸¸å®¹é‡çš„æé™æµ‹è¯•

3. **å®¹é‡æµ‹è¯•ï¼ˆVolume Testingï¼‰**ï¼š
   - **ç›®çš„**ï¼šéªŒè¯ç³»ç»Ÿå¤„ç†å¤§é‡æ•°æ®çš„èƒ½åŠ›
   - **è´Ÿè½½ç‰¹ç‚¹**ï¼šå¤§æ•°æ®é‡ï¼Œæ­£å¸¸å¹¶å‘æ•°
   - **å…³æ³¨æŒ‡æ ‡**ï¼šæ•°æ®å¤„ç†èƒ½åŠ›ã€å­˜å‚¨æ€§èƒ½ã€æŸ¥è¯¢æ•ˆç‡
   - **æµ‹è¯•åœºæ™¯**ï¼šå¤§æ•°æ®é›†ä¸‹çš„åŠŸèƒ½éªŒè¯

**å®é™…åº”ç”¨å¯¹æ¯”**ï¼š
```python
# æ€§èƒ½æµ‹è¯•ç­–ç•¥è®¾è®¡
class PerformanceTestStrategy:
    def __init__(self, system_info):
        self.expected_users = system_info.get('expected_users', 1000)
        self.peak_users = system_info.get('peak_users', 2000)
        self.data_volume = system_info.get('data_volume', '1TB')
        
    def design_load_test(self):
        """è®¾è®¡è´Ÿè½½æµ‹è¯•æ–¹æ¡ˆ"""
        return {
            'test_type': 'Load Testing',
            'concurrent_users': self.expected_users,
            'duration': '30 minutes',
            'ramp_up': '5 minutes',
            'scenarios': [
                'Normal user browsing',
                'Peak hour traffic simulation',
                'Typical business transactions'
            ],
            'success_criteria': {
                'response_time_95th': '<2s',
                'error_rate': '<1%',
                'cpu_usage': '<70%',
                'memory_usage': '<80%'
            }
        }
    
    def design_stress_test(self):
        """è®¾è®¡å‹åŠ›æµ‹è¯•æ–¹æ¡ˆ"""
        return {
            'test_type': 'Stress Testing',
            'user_pattern': 'Gradual increase from 0 to failure',
            'increment_step': '100 users per 2 minutes',
            'scenarios': [
                'Find breaking point',
                'System recovery testing',
                'Graceful degradation validation'
            ],
            'success_criteria': {
                'max_users_supported': f'>{self.peak_users * 1.5}',
                'graceful_degradation': 'No data loss',
                'recovery_time': '<5 minutes'
            }
        }
    
    def design_volume_test(self):
        """è®¾è®¡å®¹é‡æµ‹è¯•æ–¹æ¡ˆ"""
        return {
            'test_type': 'Volume Testing',
            'data_scenarios': [
                'Large dataset import',
                'Bulk operations',
                'Report generation with big data',
                'Search performance with large index'
            ],
            'test_data': {
                'user_records': '10M+',
                'transaction_history': '100M+',
                'file_storage': self.data_volume
            },
            'success_criteria': {
                'query_response': '<5s for complex queries',
                'import_speed': '>10K records/minute',
                'storage_efficiency': 'No significant degradation'
            }
        }

# JMeteræµ‹è¯•è®¡åˆ’ç¤ºä¾‹
"""
è´Ÿè½½æµ‹è¯•è®¡åˆ’ç»“æ„ï¼š
Test Plan
â”œâ”€â”€ Thread Group (1000 users, 300s ramp-up, 1800s duration)
â”‚   â”œâ”€â”€ HTTP Request Defaults
â”‚   â”œâ”€â”€ User Defined Variables  
â”‚   â”œâ”€â”€ CSV Data Set Config (test data)
â”‚   â””â”€â”€ Business Scenarios
â”‚       â”œâ”€â”€ Login Flow (10% weight)
â”‚       â”œâ”€â”€ Browse Products (40% weight)  
â”‚       â”œâ”€â”€ Search Products (30% weight)
â”‚       â””â”€â”€ Purchase Flow (20% weight)
â”œâ”€â”€ Listeners
â”‚   â”œâ”€â”€ Aggregate Report
â”‚   â”œâ”€â”€ Response Times Over Time
â”‚   â””â”€â”€ Active Threads Over Time
â””â”€â”€ Backend Listener (InfluxDB/Grafana)

å‹åŠ›æµ‹è¯•è®¡åˆ’ç»“æ„ï¼š
Test Plan  
â”œâ”€â”€ Ultimate Thread Group (æ­¥è¿›è´Ÿè½½)
â”‚   â”œâ”€â”€ Start: 0 users
â”‚   â”œâ”€â”€ Step: +100 users every 120s
â”‚   â”œâ”€â”€ Continue until error rate >5%
â”‚   â””â”€â”€ Same business scenarios as load test
â”œâ”€â”€ Constant Throughput Timer
â””â”€â”€ Enhanced monitoring listeners
"""
```

**æµ‹è¯•åœºæ™¯é€‰æ‹©ç­–ç•¥**ï¼š
```python
def choose_performance_test_type(business_context):
    """æ ¹æ®ä¸šåŠ¡åœºæ™¯é€‰æ‹©æµ‹è¯•ç±»å‹"""
    
    scenarios = {
        'new_system_validation': ['load_test', 'stress_test'],
        'capacity_planning': ['load_test', 'volume_test'],  
        'system_limits_exploration': ['stress_test'],
        'production_readiness': ['load_test', 'stress_test', 'volume_test'],
        'regression_testing': ['load_test'],
        'architecture_validation': ['stress_test', 'volume_test']
    }
    
    context_type = business_context.get('scenario_type')
    recommended_tests = scenarios.get(context_type, ['load_test'])
    
    return {
        'recommended_tests': recommended_tests,
        'priority_order': recommended_tests,
        'execution_sequence': 'Load -> Volume -> Stress'
    }
```

---

### â­â­â­ JMeteræ€§èƒ½æµ‹è¯•è„šæœ¬è®¾è®¡ä¸ä¼˜åŒ–
**éš¾åº¦**ï¼šâ­â­â­  
**é¢‘ç‡**ï¼šğŸ”¥ğŸ”¥ğŸ”¥

**æ ‡å‡†ç­”æ¡ˆ**ï¼š
**JMeterè„šæœ¬è®¾è®¡æœ€ä½³å®è·µ**ï¼š

1. **è„šæœ¬ç»“æ„è®¾è®¡**ï¼š
   - æ¨¡å—åŒ–ç»„ç»‡ï¼šä½¿ç”¨Test Fragmentå’ŒInclude Controllers
   - å‚æ•°åŒ–ï¼šCSVæ–‡ä»¶ã€ç”¨æˆ·å®šä¹‰å˜é‡ã€å‡½æ•°
   - äº‹åŠ¡æ§åˆ¶ï¼šTransaction ControlleråŒ…è£…ä¸šåŠ¡åœºæ™¯
   - æ•°æ®å…³è”ï¼šæ­£åˆ™è¡¨è¾¾å¼æå–å™¨ã€JSONæå–å™¨

2. **æ€§èƒ½ä¼˜åŒ–æŠ€å·§**ï¼š
   - ç¦ç”¨ä¸å¿…è¦çš„ç›‘å¬å™¨å’ŒæŸ¥çœ‹ç»“æœæ ‘
   - ä½¿ç”¨éGUIæ¨¡å¼è¿è¡Œ
   - åˆç†é…ç½®çº¿ç¨‹æ± å’Œå†…å­˜å‚æ•°
   - ä¼˜åŒ–å–æ ·å™¨é…ç½®

**JMeterè„šæœ¬ç¤ºä¾‹**ï¼š
```xml
<!-- ç”µå•†ç½‘ç«™æ€§èƒ½æµ‹è¯•è„šæœ¬ç»“æ„ -->
<jmeterTestPlan>
  <TestPlan>
    <!-- ç”¨æˆ·å®šä¹‰å˜é‡ -->
    <Arguments>
      <Argument name="base_url">https://api.example.com</Argument>
      <Argument name="test_duration">1800</Argument>
      <Argument name="ramp_up_period">300</Argument>
    </Arguments>
    
    <!-- çº¿ç¨‹ç»„ - è´Ÿè½½æ¨¡å¼ -->
    <ThreadGroup>
      <stringProp name="ThreadGroup.num_threads">1000</stringProp>
      <stringProp name="ThreadGroup.ramp_time">${ramp_up_period}</stringProp>
      <stringProp name="ThreadGroup.duration">${test_duration}</stringProp>
      
      <!-- HTTPè¯·æ±‚é»˜è®¤å€¼ -->
      <ConfigTestElement>
        <stringProp name="HTTPSampler.domain">${base_url}</stringProp>
        <stringProp name="HTTPSampler.protocol">https</stringProp>
      </ConfigTestElement>
      
      <!-- ç”¨æˆ·ç™»å½•æµç¨‹ -->
      <TransactionController name="User Login Flow">
        <!-- è·å–ç™»å½•é¡µé¢ -->
        <HTTPSamplerProxy name="Get Login Page">
          <stringProp name="HTTPSampler.path">/login</stringProp>
          <stringProp name="HTTPSampler.method">GET</stringProp>
        </HTTPSamplerProxy>
        
        <!-- æå–CSRF Token -->
        <RegexExtractor>
          <stringProp name="RegexExtractor.refname">csrf_token</stringProp>
          <stringProp name="RegexExtractor.regex">name="csrf_token" value="([^"]+)"</stringProp>
        </RegexExtractor>
        
        <!-- æ‰§è¡Œç™»å½• -->
        <HTTPSamplerProxy name="Submit Login">
          <stringProp name="HTTPSampler.path">/login</stringProp>
          <stringProp name="HTTPSampler.method">POST</stringProp>
          <elementProp name="HTTPsampler.Arguments">
            <Argument name="username">${__CSV(users.csv,0)}</Argument>
            <Argument name="password">${__CSV(users.csv,1)}</Argument>
            <Argument name="csrf_token">${csrf_token}</Argument>
          </elementProp>
        </HTTPSamplerProxy>
        
        <!-- å“åº”æ–­è¨€ -->
        <ResponseAssertion>
          <stringProp name="Assertion.test_field">Response_Data</stringProp>
          <stringProp name="Assertion.test_type">2</stringProp>
          <stringProp name="Assertion.test_string">Welcome</stringProp>
        </ResponseAssertion>
      </TransactionController>
      
      <!-- å•†å“æµè§ˆæµç¨‹ -->
      <TransactionController name="Product Browsing Flow">
        <!-- éšæœºæµè§ˆå•†å“åˆ†ç±» -->
        <RandomController>
          <HTTPSamplerProxy name="Browse Electronics">
            <stringProp name="HTTPSampler.path">/products?category=electronics</stringProp>
          </HTTPSamplerProxy>
          <HTTPSamplerProxy name="Browse Books">  
            <stringProp name="HTTPSampler.path">/products?category=books</stringProp>
          </HTTPSamplerProxy>
          <HTTPSamplerProxy name="Browse Clothing">
            <stringProp name="HTTPSampler.path">/products?category=clothing</stringProp>
          </HTTPSamplerProxy>
        </RandomController>
        
        <!-- æŸ¥çœ‹å•†å“è¯¦æƒ… -->
        <HTTPSamplerProxy name="Product Detail">
          <stringProp name="HTTPSampler.path">/products/${__Random(1,1000)}</stringProp>
        </HTTPSamplerProxy>
      </TransactionController>
      
      <!-- æœç´¢åŠŸèƒ½æµ‹è¯• -->
      <TransactionController name="Search Flow">
        <HTTPSamplerProxy name="Search Products">
          <stringProp name="HTTPSampler.path">/search</stringProp>
          <stringProp name="HTTPSampler.method">GET</stringProp>
          <elementProp name="HTTPsampler.Arguments">
            <Argument name="q">${__CSV(search_terms.csv,0)}</Argument>
            <Argument name="page">1</Argument>
            <Argument name="size">20</Argument>
          </elementProp>
        </HTTPSamplerProxy>
        
        <!-- JSONæå–å™¨è·å–æœç´¢ç»“æœ -->
        <JSONPostProcessor>
          <stringProp name="JSONPostProcessor.referenceNames">product_ids</stringProp>
          <stringProp name="JSONPostProcessor.jsonPathExprs">$.products[*].id</stringProp>
        </JSONPostProcessor>
      </TransactionController>
      
      <!-- è´­ç‰©è½¦å’Œç»“è´¦æµç¨‹ -->
      <TransactionController name="Purchase Flow">
        <!-- æ·»åŠ å•†å“åˆ°è´­ç‰©è½¦ -->
        <HTTPSamplerProxy name="Add to Cart">
          <stringProp name="HTTPSampler.path">/cart/add</stringProp>
          <stringProp name="HTTPSampler.method">POST</stringProp>
          <elementProp name="HTTPsampler.Arguments">
            <Argument name="product_id">${__V(product_ids_1)}</Argument>
            <Argument name="quantity">1</Argument>
          </elementProp>
        </HTTPSamplerProxy>
        
        <!-- æŸ¥çœ‹è´­ç‰©è½¦ -->
        <HTTPSamplerProxy name="View Cart">
          <stringProp name="HTTPSampler.path">/cart</stringProp>
        </HTTPSamplerProxy>
        
        <!-- ç»“è´¦ -->
        <HTTPSamplerProxy name="Checkout">
          <stringProp name="HTTPSampler.path">/checkout</stringProp>
          <stringProp name="HTTPSampler.method">POST</stringProp>
        </HTTPSamplerProxy>
      </TransactionController>
      
      <!-- æ€è€ƒæ—¶é—´ -->
      <GaussianRandomTimer>
        <stringProp name="ConstantTimer.delay">2000</stringProp>
        <stringProp name="RandomTimer.range">1000</stringProp>
      </GaussianRandomTimer>
      
    </ThreadGroup>
    
    <!-- ç›‘å¬å™¨é…ç½® -->
    <BackendListener>
      <stringProp name="BackendListener.classname">org.apache.jmeter.visualizers.backend.influxdb.InfluxdbBackendListenerClient</stringProp>
      <elementProp name="arguments">
        <Argument name="influxdbMetricsSender">org.apache.jmeter.visualizers.backend.influxdb.HttpMetricsSender</Argument>
        <Argument name="influxdbUrl">http://localhost:8086/write?db=jmeter</Argument>
      </elementProp>
    </BackendListener>
    
  </TestPlan>
</jmeterTestPlan>
```

**JMeterå‘½ä»¤è¡Œæ‰§è¡Œå’Œä¼˜åŒ–**ï¼š
```bash
#!/bin/bash
# JMeteræ€§èƒ½æµ‹è¯•æ‰§è¡Œè„šæœ¬

# ç¯å¢ƒé…ç½®
export HEAP="-Xms4g -Xmx4g -XX:MaxMetaspaceSize=256m"
export JVM_ARGS="-server -XX:+UseG1GC -XX:MaxGCPauseMillis=100"

# æµ‹è¯•å‚æ•°
TEST_PLAN="ecommerce_load_test.jmx"
RESULTS_FILE="results/load_test_$(date +%Y%m%d_%H%M%S).jtl" 
HTML_REPORT="results/html_report_$(date +%Y%m%d_%H%M%S)"
THREADS=1000
DURATION=1800
RAMP_UP=300

# åˆ›å»ºç»“æœç›®å½•
mkdir -p results

# æ‰§è¡Œæ€§èƒ½æµ‹è¯•
jmeter -n -t "${TEST_PLAN}" \
       -l "${RESULTS_FILE}" \
       -e -o "${HTML_REPORT}" \
       -Jthreads=${THREADS} \
       -Jduration=${DURATION} \
       -Jramp_up=${RAMP_UP} \
       -Jbase_url="https://api.example.com" \
       -Djna.nosys=true \
       -Djava.awt.headless=true

# ç»“æœåˆ†æ
echo "Test completed. Results saved to: ${RESULTS_FILE}"
echo "HTML report generated: ${HTML_REPORT}/index.html"

# æå–å…³é”®æŒ‡æ ‡
awk -F',' '
NR > 1 {
    count++
    total_time += $2
    if ($8 == "true") success++
    if ($2 > max_time) max_time = $2
    if (min_time == 0 || $2 < min_time) min_time = $2
}
END {
    print "æ€»è¯·æ±‚æ•°:", count
    print "æˆåŠŸç‡:", (success/count)*100 "%"
    print "å¹³å‡å“åº”æ—¶é—´:", total_time/count "ms"
    print "æœ€å°å“åº”æ—¶é—´:", min_time "ms"
    print "æœ€å¤§å“åº”æ—¶é—´:", max_time "ms"
}' "${RESULTS_FILE}"
```

**JMeteræ€§èƒ½ä¼˜åŒ–é…ç½®**ï¼š
```properties
# jmeter.propertiesä¼˜åŒ–é…ç½®

# JVMå†…å­˜è®¾ç½®
jmeter.memory.heap=-Xms4g -Xmx4g
jmeter.memory.metaspace=-XX:MaxMetaspaceSize=256m

# ç½‘ç»œé…ç½®ä¼˜åŒ–
httpclient4.retrycount=0
httpclient.timeout=60000
httpclient.socket.http.cps=0

# ç»“æœè¾“å‡ºä¼˜åŒ–  
jmeter.save.saveservice.output_format=xml
jmeter.save.saveservice.response_data=false
jmeter.save.saveservice.successful=true
jmeter.save.saveservice.thread_name=true
jmeter.save.saveservice.time=true
jmeter.save.saveservice.response_message=false

# çº¿ç¨‹æ± ä¼˜åŒ–
httpsampler.max_pool_size=10
httpsampler.max_redirect=3
httpsampler.max_frame_size=64000

# æ—¥å¿—çº§åˆ«è®¾ç½®
log_level.jmeter=INFO
log_level.jorphan=INFO
```

---

### â­â­â­ Locuståˆ†å¸ƒå¼è´Ÿè½½æµ‹è¯•å®ç°
**éš¾åº¦**ï¼šâ­â­â­  
**é¢‘ç‡**ï¼šğŸ”¥ğŸ”¥

**æ ‡å‡†ç­”æ¡ˆ**ï¼š
**Locustæ¡†æ¶ç‰¹ç‚¹**ï¼š
1. **Pythonç¼–å†™**ï¼šä»£ç å³æµ‹è¯•ï¼Œçµæ´»æ€§é«˜
2. **åˆ†å¸ƒå¼æ¶æ„**ï¼šæ”¯æŒå¤šæœºååŒæµ‹è¯•
3. **Web UI**ï¼šå®æ—¶ç›‘æ§å’Œæ§åˆ¶
4. **è½»é‡çº§**ï¼šèµ„æºæ¶ˆè€—å°‘ï¼Œå•æœºæ”¯æŒæ›´å¤šè™šæ‹Ÿç”¨æˆ·

**Locustæµ‹è¯•è„šæœ¬è®¾è®¡**ï¼š
```python
# locustfile.py - ç”µå•†ç½‘ç«™æ€§èƒ½æµ‹è¯•
from locust import HttpUser, task, between, events
from locust.contrib.fasthttp import FastHttpUser
import random
import json
import csv
from datetime import datetime

class EcommerceUser(HttpUser):
    """ç”µå•†ç½‘ç«™ç”¨æˆ·è¡Œä¸ºæ¨¡æ‹Ÿ"""
    
    wait_time = between(1, 5)  # ç”¨æˆ·æ“ä½œé—´éš”1-5ç§’
    
    def on_start(self):
        """ç”¨æˆ·å¼€å§‹æ—¶çš„åˆå§‹åŒ–æ“ä½œ"""
        self.login()
        self.user_data = self.load_user_data()
        
    def on_stop(self):
        """ç”¨æˆ·ç»“æŸæ—¶çš„æ¸…ç†æ“ä½œ"""
        self.logout()
    
    def load_user_data(self):
        """åŠ è½½æµ‹è¯•ç”¨æˆ·æ•°æ®"""
        try:
            with open('test_users.csv', 'r') as f:
                reader = csv.DictReader(f)
                users = list(reader)
                return random.choice(users)
        except FileNotFoundError:
            return {
                'username': f'user_{random.randint(1, 10000)}',
                'email': f'test{random.randint(1, 10000)}@example.com'
            }
    
    @task(1)
    def login(self):
        """ç”¨æˆ·ç™»å½• - æƒé‡1"""
        login_data = {
            'username': self.user_data.get('username', 'testuser'),
            'password': 'password123'
        }
        
        with self.client.post('/auth/login', 
                            json=login_data, 
                            name='ç”¨æˆ·ç™»å½•',
                            catch_response=True) as response:
            if response.status_code == 200:
                result = response.json()
                if 'token' in result:
                    self.client.headers.update({
                        'Authorization': f"Bearer {result['token']}"
                    })
                    response.success()
                else:
                    response.failure("ç™»å½•æˆåŠŸä½†æœªè¿”å›token")
            else:
                response.failure(f"ç™»å½•å¤±è´¥: {response.status_code}")
    
    @task(10)
    def browse_products(self):
        """æµè§ˆå•†å“ - æƒé‡10ï¼ˆæœ€å¸¸è§æ“ä½œï¼‰"""
        categories = ['electronics', 'books', 'clothing', 'home', 'sports']
        category = random.choice(categories)
        page = random.randint(1, 5)
        
        params = {
            'category': category,
            'page': page,
            'size': 20,
            'sort': random.choice(['price', 'name', 'rating'])
        }
        
        with self.client.get('/products', 
                           params=params,
                           name='æµè§ˆå•†å“åˆ—è¡¨') as response:
            if response.status_code == 200:
                products = response.json().get('products', [])
                if products:
                    # éšæœºæŸ¥çœ‹å•†å“è¯¦æƒ…
                    product_id = random.choice(products)['id']
                    self.view_product_detail(product_id)
    
    def view_product_detail(self, product_id):
        """æŸ¥çœ‹å•†å“è¯¦æƒ…"""
        with self.client.get(f'/products/{product_id}',
                           name='æŸ¥çœ‹å•†å“è¯¦æƒ…') as response:
            if response.status_code == 200:
                product = response.json()
                # æ¨¡æ‹Ÿç”¨æˆ·é˜…è¯»å•†å“ä¿¡æ¯çš„æ—¶é—´
                self.wait()
                
                # 30%æ¦‚ç‡æ·»åŠ åˆ°è´­ç‰©è½¦
                if random.random() < 0.3:
                    self.add_to_cart(product_id, random.randint(1, 3))
    
    @task(3)
    def search_products(self):
        """æœç´¢å•†å“ - æƒé‡3"""
        search_terms = [
            'laptop', 'phone', 'book', 'shoes', 'watch',
            'camera', 'headphones', 'tablet', 'keyboard', 'mouse'
        ]
        
        search_query = {
            'q': random.choice(search_terms),
            'page': 1,
            'size': 20
        }
        
        with self.client.get('/search',
                           params=search_query,
                           name='æœç´¢å•†å“') as response:
            if response.status_code == 200:
                results = response.json()
                # è®°å½•æœç´¢æ€§èƒ½æŒ‡æ ‡
                self.environment.events.request_success.fire(
                    request_type='Search',
                    name='æœç´¢å“åº”æ—¶é—´',
                    response_time=response.elapsed.total_seconds() * 1000,
                    response_length=len(response.content)
                )
    
    @task(2)
    def add_to_cart(self, product_id=None, quantity=1):
        """æ·»åŠ å•†å“åˆ°è´­ç‰©è½¦ - æƒé‡2"""
        if not product_id:
            product_id = random.randint(1, 1000)
            
        cart_data = {
            'product_id': product_id,
            'quantity': quantity
        }
        
        with self.client.post('/cart/add',
                            json=cart_data,
                            name='æ·»åŠ åˆ°è´­ç‰©è½¦') as response:
            if response.status_code == 201:
                # æ·»åŠ æˆåŠŸåï¼Œå¯èƒ½æŸ¥çœ‹è´­ç‰©è½¦
                if random.random() < 0.5:
                    self.view_cart()
    
    @task(1)
    def view_cart(self):
        """æŸ¥çœ‹è´­ç‰©è½¦"""
        with self.client.get('/cart', name='æŸ¥çœ‹è´­ç‰©è½¦') as response:
            if response.status_code == 200:
                cart = response.json()
                # å¦‚æœè´­ç‰©è½¦æœ‰å•†å“ï¼Œå¯èƒ½è¿›è¡Œç»“è´¦
                if cart.get('items') and random.random() < 0.2:
                    self.checkout()
    
    @task(1) 
    def checkout(self):
        """ç»“è´¦æµç¨‹"""
        checkout_data = {
            'shipping_address': {
                'street': '123 Test Street',
                'city': 'Test City',
                'zip': '12345'
            },
            'payment_method': 'credit_card'
        }
        
        with self.client.post('/checkout',
                            json=checkout_data,
                            name='ç»“è´¦') as response:
            if response.status_code == 200:
                order = response.json()
                # è®°å½•è®¢å•åˆ›å»ºæˆåŠŸäº‹ä»¶
                self.environment.events.request_success.fire(
                    request_type='Business',
                    name='è®¢å•åˆ›å»º',
                    response_time=response.elapsed.total_seconds() * 1000,
                    response_length=1
                )
    
    def logout(self):
        """ç”¨æˆ·ç™»å‡º"""
        if hasattr(self.client, 'headers') and 'Authorization' in self.client.headers:
            with self.client.post('/auth/logout', name='ç”¨æˆ·ç™»å‡º'):
                pass

# é«˜æ€§èƒ½ç”¨æˆ·ç±»ï¼ˆä½¿ç”¨FastHTTPï¼‰
class FastEcommerceUser(FastHttpUser):
    """ä½¿ç”¨FastHTTPçš„é«˜æ€§èƒ½ç”¨æˆ·ç±»"""
    
    wait_time = between(0.1, 0.5)  # æ›´çŸ­çš„ç­‰å¾…æ—¶é—´
    connection_timeout = 60.0
    network_timeout = 60.0
    
    @task
    def fast_api_call(self):
        """é«˜å¹¶å‘APIè°ƒç”¨"""
        endpoints = ['/api/products', '/api/categories', '/api/users/profile']
        endpoint = random.choice(endpoints)
        
        self.client.get(endpoint, name='Fast API Call')

# è‡ªå®šä¹‰è´Ÿè½½å½¢çŠ¶
class CustomLoadShape(LoadTestShape):
    """è‡ªå®šä¹‰è´Ÿè½½æµ‹è¯•å½¢çŠ¶"""
    
    stages = [
        {"duration": 60, "users": 100, "spawn_rate": 10},    # 1åˆ†é’Ÿå†…å¢åŠ åˆ°100ç”¨æˆ·
        {"duration": 300, "users": 100, "spawn_rate": 10},   # ä¿æŒ100ç”¨æˆ·5åˆ†é’Ÿ
        {"duration": 420, "users": 200, "spawn_rate": 10},   # å¢åŠ åˆ°200ç”¨æˆ·
        {"duration": 900, "users": 200, "spawn_rate": 10},   # ä¿æŒ200ç”¨æˆ·
        {"duration": 1020, "users": 500, "spawn_rate": 20}, # å¿«é€Ÿå¢åŠ åˆ°500ç”¨æˆ·
        {"duration": 1200, "users": 500, "spawn_rate": 20}, # ä¿æŒé«˜è´Ÿè½½
        {"duration": 1320, "users": 100, "spawn_rate": 10}, # é€æ­¥é™ä½
        {"duration": 1380, "users": 0, "spawn_rate": 10},   # ç»“æŸæµ‹è¯•
    ]
    
    def tick(self):
        run_time = self.get_run_time()
        
        for stage in self.stages:
            if run_time < stage["duration"]:
                return stage["users"], stage["spawn_rate"]
        
        return None

# äº‹ä»¶ç›‘å¬å™¨ - è‡ªå®šä¹‰æŒ‡æ ‡æ”¶é›†
@events.request_success.add_listener
def on_request_success(request_type, name, response_time, response_length, **kwargs):
    """è¯·æ±‚æˆåŠŸäº‹ä»¶å¤„ç†"""
    if response_time > 2000:  # è¶…è¿‡2ç§’çš„æ…¢è¯·æ±‚
        print(f"æ…¢è¯·æ±‚å‘Šè­¦: {name} - {response_time}ms")

@events.request_failure.add_listener  
def on_request_failure(request_type, name, response_time, response_length, exception, **kwargs):
    """è¯·æ±‚å¤±è´¥äº‹ä»¶å¤„ç†"""
    print(f"è¯·æ±‚å¤±è´¥: {name} - {exception}")

@events.test_start.add_listener
def on_test_start(environment, **kwargs):
    """æµ‹è¯•å¼€å§‹äº‹ä»¶"""
    print(f"æ€§èƒ½æµ‹è¯•å¼€å§‹: {datetime.now()}")
    
@events.test_stop.add_listener
def on_test_stop(environment, **kwargs):
    """æµ‹è¯•ç»“æŸäº‹ä»¶"""
    print(f"æ€§èƒ½æµ‹è¯•ç»“æŸ: {datetime.now()}")
    
    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    stats = environment.stats
    print(f"æ€»è¯·æ±‚æ•°: {stats.total.num_requests}")
    print(f"å¤±è´¥è¯·æ±‚æ•°: {stats.total.num_failures}")
    print(f"å¹³å‡å“åº”æ—¶é—´: {stats.total.avg_response_time:.2f}ms")
    print(f"95ç™¾åˆ†ä½å“åº”æ—¶é—´: {stats.total.get_response_time_percentile(0.95):.2f}ms")

# å‘½ä»¤è¡Œè¿è¡Œç¤ºä¾‹
"""
# å•æœºè¿è¡Œ
locust -f locustfile.py --host=https://api.example.com

# åˆ†å¸ƒå¼è¿è¡Œ - MasterèŠ‚ç‚¹
locust -f locustfile.py --host=https://api.example.com --master

# åˆ†å¸ƒå¼è¿è¡Œ - WorkerèŠ‚ç‚¹
locust -f locustfile.py --host=https://api.example.com --worker --master-host=192.168.1.100

# æ— UIæ¨¡å¼è¿è¡Œ
locust -f locustfile.py --host=https://api.example.com --headless -u 1000 -r 50 -t 30m

# ä½¿ç”¨è‡ªå®šä¹‰è´Ÿè½½å½¢çŠ¶
locust -f locustfile.py --host=https://api.example.com --headless --load-shape=CustomLoadShape
"""
```

**Locuståˆ†å¸ƒå¼éƒ¨ç½²æ¶æ„**ï¼š
```python
# master_config.py - MasterèŠ‚ç‚¹é…ç½®
import os
from locust import events
from locust.env import Environment
from locust.stats import stats_printer, stats_history
import gevent
import logging

class DistributedMaster:
    def __init__(self, host):
        self.host = host
        self.environment = Environment(user_classes=[EcommerceUser])
        
    def setup_distributed_test(self):
        """è®¾ç½®åˆ†å¸ƒå¼æµ‹è¯•ç¯å¢ƒ"""
        
        # é…ç½®MasterèŠ‚ç‚¹
        self.environment.create_master_runner(
            master_bind_host="*",
            master_bind_port=5557
        )
        
        # å¯åŠ¨Web UI
        self.environment.create_web_ui(
            host="0.0.0.0",
            port=8089
        )
        
        # è®¾ç½®ç»Ÿè®¡ä¿¡æ¯æ‰“å°
        gevent.spawn(stats_printer(self.environment.stats))
        gevent.spawn(stats_history, self.environment.runner)
        
        return self.environment

# worker_config.py - WorkerèŠ‚ç‚¹é…ç½®  
class DistributedWorker:
    def __init__(self, master_host, master_port=5557):
        self.master_host = master_host
        self.master_port = master_port
        self.environment = Environment(user_classes=[EcommerceUser])
        
    def setup_worker(self):
        """è®¾ç½®WorkerèŠ‚ç‚¹"""
        
        self.environment.create_worker_runner(
            master_host=self.master_host,
            master_port=self.master_port
        )
        
        return self.environment

# docker-compose.yml - å®¹å™¨åŒ–éƒ¨ç½²
"""
version: '3.8'
services:
  locust-master:
    image: locustio/locust
    ports:
      - "8089:8089"
      - "5557:5557"
    volumes:
      - ./locustfile.py:/mnt/locust/locustfile.py
      - ./test_data:/mnt/locust/test_data
    command: -f /mnt/locust/locustfile.py --master --host=https://api.example.com
    environment:
      - LOCUST_HOST=https://api.example.com
      
  locust-worker1:
    image: locustio/locust  
    volumes:
      - ./locustfile.py:/mnt/locust/locustfile.py
      - ./test_data:/mnt/locust/test_data
    command: -f /mnt/locust/locustfile.py --worker --master-host=locust-master
    depends_on:
      - locust-master
      
  locust-worker2:
    image: locustio/locust
    volumes:
      - ./locustfile.py:/mnt/locust/locustfile.py  
      - ./test_data:/mnt/locust/test_data
    command: -f /mnt/locust/locustfile.py --worker --master-host=locust-master
    depends_on:
      - locust-master
"""
```

---

### â­â­â­ æ€§èƒ½æµ‹è¯•æŒ‡æ ‡ä½“ç³»ä¸åˆ†ææ–¹æ³•
**éš¾åº¦**ï¼šâ­â­â­  
**é¢‘ç‡**ï¼šğŸ”¥ğŸ”¥ğŸ”¥

**æ ‡å‡†ç­”æ¡ˆ**ï¼š
**æ€§èƒ½æŒ‡æ ‡åˆ†ç±»ä½“ç³»**ï¼š

1. **å“åº”æ€§èƒ½æŒ‡æ ‡**ï¼š
   - **å¹³å‡å“åº”æ—¶é—´**ï¼šæ‰€æœ‰è¯·æ±‚å“åº”æ—¶é—´çš„ç®—æœ¯å¹³å‡å€¼
   - **ç™¾åˆ†ä½å“åº”æ—¶é—´**ï¼šP50ã€P90ã€P95ã€P99å“åº”æ—¶é—´
   - **æœ€å¤§å“åº”æ—¶é—´**ï¼šæµ‹è¯•æœŸé—´çš„æœ€é•¿å“åº”æ—¶é—´
   - **æœ€å°å“åº”æ—¶é—´**ï¼šæµ‹è¯•æœŸé—´çš„æœ€çŸ­å“åº”æ—¶é—´

2. **ååé‡æŒ‡æ ‡**ï¼š
   - **TPSï¼ˆTransaction Per Secondï¼‰**ï¼šæ¯ç§’äº‹åŠ¡æ•°
   - **RPSï¼ˆRequest Per Secondï¼‰**ï¼šæ¯ç§’è¯·æ±‚æ•°
   - **QPSï¼ˆQuery Per Secondï¼‰**ï¼šæ¯ç§’æŸ¥è¯¢æ•°
   - **å¸¦å®½åˆ©ç”¨ç‡**ï¼šç½‘ç»œå¸¦å®½ä½¿ç”¨æƒ…å†µ

3. **å¹¶å‘æ€§èƒ½æŒ‡æ ‡**ï¼š
   - **å¹¶å‘ç”¨æˆ·æ•°**ï¼šåŒæ—¶åœ¨çº¿ç”¨æˆ·æ•°é‡
   - **æ´»è·ƒç”¨æˆ·æ•°**ï¼šæ­£åœ¨æ‰§è¡Œæ“ä½œçš„ç”¨æˆ·æ•°
   - **è¿æ¥æ•°**ï¼šæ•°æ®åº“/æœåŠ¡å™¨è¿æ¥æ•°
   - **çº¿ç¨‹æ•°**ï¼šåº”ç”¨æœåŠ¡å™¨çº¿ç¨‹ä½¿ç”¨æƒ…å†µ

4. **ç¨³å®šæ€§æŒ‡æ ‡**ï¼š
   - **é”™è¯¯ç‡**ï¼šå¤±è´¥è¯·æ±‚å æ€»è¯·æ±‚çš„ç™¾åˆ†æ¯”
   - **å¯ç”¨æ€§**ï¼šç³»ç»Ÿæ­£å¸¸è¿è¡Œæ—¶é—´å æ¯”
   - **èµ„æºåˆ©ç”¨ç‡**ï¼šCPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œä½¿ç”¨ç‡

**æ€§èƒ½æŒ‡æ ‡åˆ†ææ¡†æ¶**ï¼š
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta

class PerformanceAnalyzer:
    def __init__(self, test_results_file):
        self.df = pd.read_csv(test_results_file)
        self.df['timestamp'] = pd.to_datetime(self.df['timestamp'])
        self.df['success'] = self.df['success'].astype(bool)
        
    def calculate_basic_metrics(self):
        """è®¡ç®—åŸºç¡€æ€§èƒ½æŒ‡æ ‡"""
        total_requests = len(self.df)
        successful_requests = len(self.df[self.df['success'] == True])
        failed_requests = total_requests - successful_requests
        
        response_times = self.df[self.df['success']]['response_time']
        
        metrics = {
            'total_requests': total_requests,
            'successful_requests': successful_requests,
            'failed_requests': failed_requests,
            'success_rate': (successful_requests / total_requests) * 100,
            'error_rate': (failed_requests / total_requests) * 100,
            'avg_response_time': response_times.mean(),
            'min_response_time': response_times.min(),
            'max_response_time': response_times.max(),
            'p50_response_time': response_times.quantile(0.50),
            'p90_response_time': response_times.quantile(0.90),
            'p95_response_time': response_times.quantile(0.95),
            'p99_response_time': response_times.quantile(0.99),
            'std_response_time': response_times.std()
        }
        
        return metrics
    
    def calculate_throughput_metrics(self):
        """è®¡ç®—ååé‡æŒ‡æ ‡"""
        # æŒ‰æ—¶é—´çª—å£ç»Ÿè®¡ååé‡
        self.df['minute'] = self.df['timestamp'].dt.floor('min')
        throughput_by_minute = self.df.groupby('minute').size()
        
        # è®¡ç®—TPSï¼ˆæ¯åˆ†é’Ÿè¯·æ±‚æ•°/60ï¼‰
        tps_data = throughput_by_minute / 60
        
        return {
            'avg_tps': tps_data.mean(),
            'max_tps': tps_data.max(),
            'min_tps': tps_data.min(),
            'tps_std': tps_data.std(),
            'total_duration': (self.df['timestamp'].max() - 
                             self.df['timestamp'].min()).total_seconds()
        }
    
    def analyze_performance_trends(self):
        """åˆ†ææ€§èƒ½è¶‹åŠ¿"""
        # æ—¶é—´åºåˆ—åˆ†æ
        self.df['minute'] = self.df['timestamp'].dt.floor('min')
        
        trend_analysis = self.df.groupby(['minute', 'success']).agg({
            'response_time': ['mean', 'count', 'std'],
            'timestamp': 'count'
        }).reset_index()
        
        return trend_analysis
    
    def detect_performance_issues(self):
        """æ£€æµ‹æ€§èƒ½é—®é¢˜"""
        issues = []
        metrics = self.calculate_basic_metrics()
        
        # æ£€æµ‹é”™è¯¯ç‡è¿‡é«˜
        if metrics['error_rate'] > 5:
            issues.append({
                'type': 'High Error Rate',
                'severity': 'Critical' if metrics['error_rate'] > 10 else 'Major',
                'value': f"{metrics['error_rate']:.2f}%",
                'threshold': '5%'
            })
        
        # æ£€æµ‹å“åº”æ—¶é—´è¿‡é•¿
        if metrics['p95_response_time'] > 2000:
            issues.append({
                'type': 'High Response Time', 
                'severity': 'Critical' if metrics['p95_response_time'] > 5000 else 'Major',
                'value': f"{metrics['p95_response_time']:.0f}ms",
                'threshold': '2000ms'
            })
        
        # æ£€æµ‹å“åº”æ—¶é—´å˜å¼‚è¿‡å¤§
        cv = metrics['std_response_time'] / metrics['avg_response_time']
        if cv > 1.0:
            issues.append({
                'type': 'High Response Time Variability',
                'severity': 'Major',
                'value': f"{cv:.2f}",
                'threshold': '1.0'
            })
        
        # æ£€æµ‹ååé‡ä¸‹é™
        throughput_metrics = self.calculate_throughput_metrics()
        tps_trend = self.calculate_tps_trend()
        if tps_trend['slope'] < -0.1:  # TPSä¸‹é™è¶…è¿‡10%
            issues.append({
                'type': 'Declining Throughput',
                'severity': 'Major',
                'value': f"{tps_trend['slope']:.3f} TPS/min",
                'threshold': '-0.1 TPS/min'
            })
        
        return issues
    
    def calculate_tps_trend(self):
        """è®¡ç®—TPSè¶‹åŠ¿"""
        self.df['minute'] = self.df['timestamp'].dt.floor('min')
        tps_by_minute = self.df.groupby('minute').size() / 60
        
        # çº¿æ€§å›å½’è®¡ç®—è¶‹åŠ¿
        x = np.arange(len(tps_by_minute))
        slope, intercept = np.polyfit(x, tps_by_minute, 1)
        
        return {
            'slope': slope,
            'intercept': intercept,
            'r_squared': np.corrcoef(x, tps_by_minute)[0, 1] ** 2
        }
    
    def generate_performance_report(self):
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
        metrics = self.calculate_basic_metrics()
        throughput = self.calculate_throughput_metrics() 
        issues = self.detect_performance_issues()
        
        report = f"""
# æ€§èƒ½æµ‹è¯•åˆ†ææŠ¥å‘Š

## æµ‹è¯•æ¦‚è¿°
- æµ‹è¯•æ—¶é—´: {self.df['timestamp'].min()} è‡³ {self.df['timestamp'].max()}
- æµ‹è¯•æŒç»­æ—¶é—´: {throughput['total_duration']:.0f} ç§’
- æ€»è¯·æ±‚æ•°: {metrics['total_requests']:,}

## å“åº”æ—¶é—´åˆ†æ
- å¹³å‡å“åº”æ—¶é—´: {metrics['avg_response_time']:.2f} ms
- P50å“åº”æ—¶é—´: {metrics['p50_response_time']:.2f} ms
- P95å“åº”æ—¶é—´: {metrics['p95_response_time']:.2f} ms
- P99å“åº”æ—¶é—´: {metrics['p99_response_time']:.2f} ms
- æœ€å¤§å“åº”æ—¶é—´: {metrics['max_response_time']:.2f} ms

## ååé‡åˆ†æ
- å¹³å‡TPS: {throughput['avg_tps']:.2f}
- æœ€å¤§TPS: {throughput['max_tps']:.2f}
- æœ€å°TPS: {throughput['min_tps']:.2f}

## é”™è¯¯ç‡åˆ†æ
- æˆåŠŸç‡: {metrics['success_rate']:.2f}%
- é”™è¯¯ç‡: {metrics['error_rate']:.2f}%
- æˆåŠŸè¯·æ±‚æ•°: {metrics['successful_requests']:,}
- å¤±è´¥è¯·æ±‚æ•°: {metrics['failed_requests']:,}

## å‘ç°çš„æ€§èƒ½é—®é¢˜
"""
        
        if issues:
            for i, issue in enumerate(issues, 1):
                report += f"""
{i}. **{issue['type']}** ({issue['severity']})
   - å½“å‰å€¼: {issue['value']}
   - é˜ˆå€¼: {issue['threshold']}
"""
        else:
            report += "\nâœ… æœªå‘ç°é‡å¤§æ€§èƒ½é—®é¢˜\n"
        
        return report
    
    def create_performance_dashboard(self):
        """åˆ›å»ºæ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # å“åº”æ—¶é—´åˆ†å¸ƒ
        self.df[self.df['success']]['response_time'].hist(bins=50, ax=axes[0,0])
        axes[0,0].set_title('å“åº”æ—¶é—´åˆ†å¸ƒ')
        axes[0,0].set_xlabel('å“åº”æ—¶é—´ (ms)')
        axes[0,0].set_ylabel('é¢‘æ¬¡')
        
        # å“åº”æ—¶é—´è¶‹åŠ¿
        self.df.set_index('timestamp')['response_time'].resample('1min').mean().plot(ax=axes[0,1])
        axes[0,1].set_title('å“åº”æ—¶é—´è¶‹åŠ¿')
        axes[0,1].set_xlabel('æ—¶é—´')
        axes[0,1].set_ylabel('å¹³å‡å“åº”æ—¶é—´ (ms)')
        
        # TPSè¶‹åŠ¿
        tps_trend = self.df.set_index('timestamp').resample('1min').size() / 60
        tps_trend.plot(ax=axes[0,2])
        axes[0,2].set_title('TPSè¶‹åŠ¿')
        axes[0,2].set_xlabel('æ—¶é—´')
        axes[0,2].set_ylabel('TPS')
        
        # é”™è¯¯ç‡è¶‹åŠ¿
        error_rate = self.df.groupby(self.df['timestamp'].dt.floor('min')).apply(
            lambda x: (1 - x['success'].mean()) * 100
        )
        error_rate.plot(ax=axes[1,0], color='red')
        axes[1,0].set_title('é”™è¯¯ç‡è¶‹åŠ¿')
        axes[1,0].set_xlabel('æ—¶é—´')
        axes[1,0].set_ylabel('é”™è¯¯ç‡ (%)')
        
        # å“åº”æ—¶é—´ç™¾åˆ†ä½æ•°
        percentiles = [50, 75, 90, 95, 99]
        response_times = self.df[self.df['success']]['response_time']
        percentile_values = [response_times.quantile(p/100) for p in percentiles]
        
        axes[1,1].bar(percentiles, percentile_values)
        axes[1,1].set_title('å“åº”æ—¶é—´ç™¾åˆ†ä½æ•°')
        axes[1,1].set_xlabel('ç™¾åˆ†ä½æ•°')
        axes[1,1].set_ylabel('å“åº”æ—¶é—´ (ms)')
        
        # è¯·æ±‚ç±»å‹åˆ†å¸ƒ
        if 'request_type' in self.df.columns:
            request_counts = self.df['request_type'].value_counts()
            axes[1,2].pie(request_counts.values, labels=request_counts.index, autopct='%1.1f%%')
            axes[1,2].set_title('è¯·æ±‚ç±»å‹åˆ†å¸ƒ')
        
        plt.tight_layout()
        return fig

# ä½¿ç”¨ç¤ºä¾‹
analyzer = PerformanceAnalyzer('performance_test_results.csv')
metrics = analyzer.calculate_basic_metrics()
report = analyzer.generate_performance_report()
dashboard = analyzer.create_performance_dashboard()

print(report)
plt.show()
```

---

## ä¸“é¢˜æ€»ç»“

è´Ÿè½½ä¸å‹åŠ›æµ‹è¯•æ˜¯æ€§èƒ½ä¿éšœçš„æ ¸å¿ƒæŠ€èƒ½ï¼Œéœ€è¦æŒæ¡ï¼š

1. **ç†è®ºåŸºç¡€**ï¼šæ·±å…¥ç†è§£ä¸åŒç±»å‹æ€§èƒ½æµ‹è¯•çš„ç›®çš„å’Œåº”ç”¨åœºæ™¯
2. **å·¥å…·ä½¿ç”¨**ï¼šç†Ÿç»ƒæŒæ¡JMeterã€Locustç­‰ä¸»æµæ€§èƒ½æµ‹è¯•å·¥å…·
3. **è„šæœ¬è®¾è®¡**ï¼šèƒ½å¤Ÿè®¾è®¡çœŸå®ä¸šåŠ¡åœºæ™¯çš„æ€§èƒ½æµ‹è¯•è„šæœ¬
4. **æŒ‡æ ‡åˆ†æ**ï¼šå»ºç«‹å®Œæ•´çš„æ€§èƒ½æŒ‡æ ‡ä½“ç³»å’Œåˆ†ææ–¹æ³•
5. **é—®é¢˜è¯Šæ–­**ï¼šå…·å¤‡æ€§èƒ½ç“¶é¢ˆè¯†åˆ«å’Œé—®é¢˜å®šä½èƒ½åŠ›

**é¢è¯•å›ç­”è¦ç‚¹**ï¼š
- å±•ç¤ºå¯¹æ€§èƒ½æµ‹è¯•ç†è®ºçš„æ·±åº¦ç†è§£
- ç»“åˆå…·ä½“é¡¹ç›®è¯´æ˜å·¥å…·é€‰å‹å’Œä½¿ç”¨ç»éªŒ
- å¼ºè°ƒæµ‹è¯•ç»“æœåˆ†æå’Œæ€§èƒ½è°ƒä¼˜çš„å®æˆ˜èƒ½åŠ›
- ä½“ç°ç³»ç»Ÿæ€§èƒ½è§„åˆ’å’Œå®¹é‡ç®¡ç†çš„æˆ˜ç•¥æ€ç»´