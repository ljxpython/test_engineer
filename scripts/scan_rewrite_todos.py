#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰«æ resume_template ä¸‹çš„ Markdownï¼Œè‡ªåŠ¨ç”Ÿæˆâ€œæ”¹å†™å¾…åŠâ€æ¸…å•ï¼š
- è§„åˆ™ï¼š
  1) å‘½ä¸­â€œæ ‡å‡†å›ç­”â€å…³é”®å­—ï¼Œæˆ–
  2) åŒä¸€å°èŠ‚å†…å­˜åœ¨ä¸‰å¼•å·ä»£ç å›´æ ï¼ˆ```ï¼‰ï¼Œä¸”é‚»è¿‘å‡ºç°â€œé—®é¢˜ï¼šâ€/â€œæ ‡å‡†å›ç­”ï¼šâ€
- è¿‡æ»¤ï¼šè‹¥å°èŠ‚å·²å­˜åœ¨â€œå›ç­”ï¼ˆå£è¿°ç‰ˆï¼ŒSTARï¼‰â€ä¸”æ— ä»£ç å›´æ ï¼Œåˆ™è§†ä¸ºå·²æ”¹å†™ï¼Œè·³è¿‡
- è¾“å‡ºï¼šå†™å…¥ resume_template/auto_rewrite_todo.mdï¼ˆè¦†ç›–å†™å…¥ï¼‰

ä½¿ç”¨ï¼š
  python scripts/scan_rewrite_todos.py
"""
import re
import sys
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
BASE = ROOT / "resume_template"
OUT = BASE / "auto_rewrite_todo.md"

# å¿½ç•¥æ–‡ä»¶ï¼ˆé¿å…è‡ªå¼•ç”¨ä¸éé¢è¯•è¾“å‡ºï¼‰
IGNORE_NAMES = {
    "auto_rewrite_todo.md",
    "interview_rewrite_tracker.md",
    "interview_flashcards.md",
    "metrics_glossary_and_sources.md",
}
# å¿½ç•¥ç›®å½•åï¼ˆé¡¶å±‚æˆ–ä»»æ„å­è·¯å¾„ååŒ¹é…å³å¿½ç•¥ï¼‰
IGNORE_DIRS = {
    "03-é¢è¯•ç­–ç•¥æŒ‡å—",
}
# ç™½åå•ç›®å½•ï¼ˆä»…æ‰«æè¿™äº›ç›®å½•ï¼‰
ALLOW_DIRS = {
    "02-æŠ€æœ¯ä¸“é¢˜åº“",
    "04-é¢˜åº“ä¸ç­”æ¡ˆ",
}

HEADING_RE = re.compile(r"^(#{2,3})\s+(.*)")
STD_ANSWER_RE = re.compile(r"æ ‡å‡†å›ç­”")
STAR_ANSWER_RE = re.compile(r"å›ç­”ï¼ˆå£è¿°ç‰ˆ")

# ç®€æ˜“ä¼˜å…ˆçº§è¯„ä¼°
def classify_priority(title: str) -> str:
    flames = title.count("ğŸ”¥")
    stars = title.count("â­")
    if flames >= 2 or stars >= 3:
        return "é«˜"
    if flames >= 1 or stars >= 2:
        return "ä¸­"
    return "ä½"

QUESTION_RE = re.compile(r"é—®é¢˜ï¼š")
CODE_FENCE_RE = re.compile(r"^```")

MAX_CONTEXT = 30  # åŒä¸€å°èŠ‚å†…å‰åæ–‡çª—å£


def nearest_heading(lines, idx):
    """å‘ä¸Šæ‰¾åˆ°æœ€è¿‘çš„äºŒ/ä¸‰çº§æ ‡é¢˜ã€‚è¿”å› 1-based è¡Œå·ã€å±‚çº§ä¸æ ‡é¢˜ã€‚"""
    for i in range(idx, -1, -1):
        m = HEADING_RE.match(lines[i])
        if m:
            level = len(m.group(1))
            title = m.group(2).strip()
            return (i + 1, level, title)
    return (None, None, None)


def find_next_heading(lines, start_idx):
    """ä» start_idx+1 å‘ä¸‹æ‰¾åˆ°ä¸‹ä¸€ä¸ªæ ‡é¢˜ï¼ˆä»»æ„å±‚çº§ï¼‰ã€‚è¿”å› 0-based è¡Œå·æˆ– len(lines)ã€‚"""
    for j in range(start_idx + 1, len(lines)):
        if HEADING_RE.match(lines[j]):
            return j
    return len(lines)


def get_section_slice(lines, heading_line_1based):
    """åŸºäºæ ‡é¢˜è¡Œï¼ˆ1-basedï¼‰è¿”å›è¯¥å°èŠ‚çš„æ–‡æœ¬åˆ‡ç‰‡ä¸æ˜¯å¦å«ä»£ç å›´æ ã€‚"""
    if not heading_line_1based:
        return "", False
    h0 = heading_line_1based - 1
    end = find_next_heading(lines, h0)
    section_lines = lines[h0:end]
    section_text = "\n".join(section_lines)
    has_code_fence = any(CODE_FENCE_RE.match(ln) for ln in section_lines)
    return section_text, has_code_fence


def scan_file(path: Path):
    text = path.read_text(encoding="utf-8", errors="ignore")
    lines = text.splitlines()
    hits = []

    code_fence_lines = [i for i, ln in enumerate(lines) if CODE_FENCE_RE.match(ln)]
    std_answer_lines = [i for i, ln in enumerate(lines) if STD_ANSWER_RE.search(ln)]

    # 1) ç›´æ¥å‘½ä¸­â€œæ ‡å‡†å›ç­”â€
    for i in std_answer_lines:
        h_line, level, title = nearest_heading(lines, i)
        section_text, has_code = get_section_slice(lines, h_line)
        # è‹¥å·²æ˜¯å£è¿°ç‰ˆä¸”æ— ä»£ç ï¼Œåˆ™è·³è¿‡ï¼ˆè§†ä¸ºå·²æ”¹å†™ï¼‰
        if STAR_ANSWER_RE.search(section_text) and not has_code:
            continue
        hits.append({
            "reason": "æ ‡å‡†å›ç­”",
            "heading": title or "(æœªå‘½åå°èŠ‚)",
            "line": h_line or (i + 1),
        })

    # 2) å­˜åœ¨ä»£ç å›´æ ï¼Œä¸”é‚»è¿‘å‡ºç°â€œé—®é¢˜ï¼š/æ ‡å‡†å›ç­”ï¼šâ€
    for i in code_fence_lines:
        start = max(0, i - MAX_CONTEXT)
        end = min(len(lines), i + MAX_CONTEXT)
        window = "\n".join(lines[start:end])
        # æ”¶ç´§è§„åˆ™ï¼šåŒä¸€çª—å£å†…å¿…é¡»åŒæ—¶å‡ºç°â€œé—®é¢˜ï¼šâ€ä¸â€œæ ‡å‡†å›ç­”â€æ‰å‘½ä¸­
        if QUESTION_RE.search(window) and STD_ANSWER_RE.search(window):
            h_line, level, title = nearest_heading(lines, i)
            section_text, has_code = get_section_slice(lines, h_line)
            # è‹¥è¯¥å°èŠ‚å·²æ˜¯å£è¿°ç‰ˆï¼ˆå­˜åœ¨â€œå›ç­”ï¼ˆå£è¿°ç‰ˆâ€ï¼‰ï¼Œåˆ™è·³è¿‡
            if STAR_ANSWER_RE.search(section_text):
                continue
            hits.append({
                "reason": "ä»£ç å›´æ +é—®ç­”è¯­ä¹‰(åŒæ¡ä»¶)",
                "heading": title or "(æœªå‘½åå°èŠ‚)",
                "line": h_line or (i + 1),
            })

    # å»é‡ï¼ˆæŒ‰ heading+line èšåˆï¼‰
    uniq = {}
    for h in hits:
        key = (h["heading"], h["line"])
        if key not in uniq:
            uniq[key] = h
    hits = list(uniq.values())
    if not hits:
        return None

    # æ„é€  markdown ç‰‡æ®µ
    rel = path.relative_to(ROOT)
    lines_out = [f"- {rel}"]
    for h in sorted(hits, key=lambda x: x["line"]):
        prio = classify_priority(h['heading'] or '')
        lines_out.append(f"  - å°èŠ‚ï¼š{h['heading']} (è¡Œ {h['line']}) | åŸå› ï¼š{h['reason']} | ä¼˜å…ˆçº§ï¼š{prio}")
    return "\n".join(lines_out)


def main():
    if not BASE.exists():
        print(f"ç›®å½•ä¸å­˜åœ¨ï¼š{BASE}", file=sys.stderr)
        sys.exit(1)

    md_files = [
        p for p in BASE.rglob("*.md")
        if p.name not in IGNORE_NAMES
        and not any(part in IGNORE_DIRS for part in p.parts)
        and any(part in ALLOW_DIRS for part in p.parts)
    ]
    md_files.sort()

    sections = []
    for p in md_files:
        frag = scan_file(p)
        if frag:
            sections.append(frag)

    header = [
        "# è‡ªåŠ¨æ‰«ææ”¹å†™å¾…åŠ",
        "",
        "> è¯´æ˜ï¼šä»¥ä¸‹æ¡ç›®ç”±è„šæœ¬æ ¹æ®â€˜æ ‡å‡†å›ç­”â€™å…³é”®å­—ä¸â€˜ä»£ç å›´æ +é—®ç­”è¯­ä¹‰â€™è§„åˆ™è‡ªåŠ¨æ±‡æ€»ï¼Œä»…ä¾›å‚è€ƒã€‚",
        "> å»ºè®®ç»“åˆ interview_rewrite_tracker.md çš„èŒƒå›´ä¸æ’é™¤è§„åˆ™äººå·¥å¤æ ¸ã€‚",
        "",
    ]

    content = "\n\n".join([*header, *sections]) if sections else "\n".join([*header, "(æœªå‘ç°ç–‘ä¼¼æ”¹å†™æ¡ç›®)"])
    OUT.write_text(content, encoding="utf-8")
    print(f"å·²ç”Ÿæˆï¼š{OUT}")


if __name__ == "__main__":
    main()
